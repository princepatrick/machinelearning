{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErZPnYadWO4Z",
        "outputId": "b0b2fb4a-fc8e-4996-9be2-4311669db834"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 34\n",
        "\n",
        "MAX_LEN = 70"
      ],
      "metadata": {
        "id": "sXvdQlBiN5F_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequence = \"I don't know about you, but there's only one thing I want to do after a long day of work\""
      ],
      "metadata": {
        "id": "U_7mu591OALt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-large\")\n",
        "gpt2 = TFGPT2LMHeadModel.from_pretrained(\"gpt2-large\", pad_token_id= tokenizer.eos_token_id)\n",
        "\n",
        "gpt2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PaAE33wPYx-",
        "outputId": "261fd969-f63e-4fca-b5b8-cc31c57502b9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tfgpt2lm_head_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " transformer (TFGPT2MainLaye  multiple                 774030080 \n",
            " r)                                                              \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 774,030,080\n",
            "Trainable params: 774,030,080\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.random.set_seed(SEED)"
      ],
      "metadata": {
        "id": "ARQX9_7YQ8oq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Greedy Search"
      ],
      "metadata": {
        "id": "WV568ksHS4N6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer.encode(input_sequence, return_tensors='tf')\n",
        "\n",
        "greedy_output = gpt2.generate(input_ids, max_length=MAX_LEN)\n",
        "\n",
        "print(\"-\" * 100 )\n",
        "\n",
        "print(tokenizer.decode( greedy_output[0], skip_special_tokens = True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLjyPKTHRH0k",
        "outputId": "ac348a8e-d436-4e29-cb82-101dcaf4a6b2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "I don't know about you, but there's only one thing I want to do after a long day of work: go to the gym.\n",
            "\n",
            "I'm not talking about the gym that's right next to my house. I'm talking about the gym that's right next to my office.\n",
            "\n",
            "I'm not talking about the gym that\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Beam Search with N-Gram penalties"
      ],
      "metadata": {
        "id": "N_jfwPXmS6h-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "beam_outputs = gpt2.generate(\n",
        "    input_ids,\n",
        "    max_length = MAX_LEN,\n",
        "    num_beams = 5,\n",
        "    no_repeat_ngram_size = 2,\n",
        "    num_return_sequences = 5,\n",
        "    early_stopping = True\n",
        ")\n",
        "\n",
        "print('')\n",
        "print('*' * 100)\n",
        "\n",
        "for i, beam_output in enumerate(beam_outputs):\n",
        "  print(\"{}: {}\".format( i,\n",
        "                        tokenizer.decode(beam_output, skip_special_tokens=True)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPrq6V96S6Df",
        "outputId": "8665ba1c-1f1e-4204-c7aa-e22bb66c3f89"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "****************************************************************************************************\n",
            "0: I don't know about you, but there's only one thing I want to do after a long day of work, and that's to sit down and watch a movie.\"\n",
            "\n",
            "\"I know, I know,\" you say. \"But you're not going to like this one. It's not a good movie. I mean, it's\n",
            "1: I don't know about you, but there's only one thing I want to do after a long day of work, and that's to sit down and watch a movie.\"\n",
            "\n",
            "\"I know, I know,\" you say. \"But you're not going to like this one. It's about a guy who has a crush on a girl\n",
            "2: I don't know about you, but there's only one thing I want to do after a long day of work, and that's to sit down and watch a movie.\"\n",
            "\n",
            "\"I know, I know,\" you say. \"But you're not going to like this one. It's about a guy who has a crush on a woman\n",
            "3: I don't know about you, but there's only one thing I want to do after a long day of work, and that's to sit down and watch a movie.\"\n",
            "\n",
            "\"I know, I know,\" you say. \"But you're not going to like this one. It's about a guy who has a crush on a beautiful\n",
            "4: I don't know about you, but there's only one thing I want to do after a long day of work, and that's to sit down and watch a movie.\"\n",
            "\n",
            "\"I know, I know,\" you say. \"But you're not going to like this one. It's not a good movie. I'm not sure if\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic Sampling"
      ],
      "metadata": {
        "id": "4_nHhsHcT_4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_output = gpt2.generate(\n",
        "    input_ids,\n",
        "    do_sample = True,\n",
        "    max_length = MAX_LEN,\n",
        "    top_k = 0,\n",
        "    temperature = 0.8\n",
        ")\n",
        "\n",
        "print(\"*\"*100)\n",
        "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76dTiy_fUBak",
        "outputId": "1db07796-488f-42af-b31c-1959dfbf00c4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****************************************************************************************************\n",
            "I don't know about you, but there's only one thing I want to do after a long day of work: cry.\"\n",
            "\n",
            "It's not the first time that guy has been caught stretching—he's even been arrested for it in the last year—but this story totally made us laugh.\n",
            "\n",
            "And we mean \"laugh\" in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top-K Sampling"
      ],
      "metadata": {
        "id": "X6zczsNrWW9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_output_top_k = gpt2.generate(\n",
        "    input_ids,\n",
        "    do_sample = True,\n",
        "    max_length = MAX_LEN,\n",
        "    top_k = 50\n",
        ")\n",
        "\n",
        "print(\"*\" * 100)\n",
        "\n",
        "print( tokenizer.decode(sample_output_top_k[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_ZfkINwWMTg",
        "outputId": "b69b565b-fd66-4ff8-b964-dc310c8641de"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****************************************************************************************************\n",
            "I don't know about you, but there's only one thing I want to do after a long day of work, and that's watch a damn football game. This is a tough team to play from time to time, but it has one of the highest winning percentages in the National Football League.\n",
            "\n",
            "I'm not the only one who thinks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top-p Sampling"
      ],
      "metadata": {
        "id": "ipPd6EyoXZRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_output_top_p = gpt2.generate(\n",
        "    input_ids,\n",
        "    do_sample = True,\n",
        "    max_length = MAX_LEN,\n",
        "    top_p = 0.8,\n",
        "    top_k = 0\n",
        ")\n",
        "\n",
        "print(\"*\" * 100)\n",
        "\n",
        "print(tokenizer.decode(sample_output_top_p[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOPOxuiQX042",
        "outputId": "61ff3e73-f4e5-4c64-a3f9-922d928b0c3f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****************************************************************************************************\n",
            "I don't know about you, but there's only one thing I want to do after a long day of work:\n",
            "\n",
            "#5. Make breakfast for the other team members\n",
            "\n",
            "Making breakfast is a habit that needs to be passed down to the next generation.\n",
            "\n",
            "\"Do you think you could make some bacon?\n",
            "\n",
            "\"I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top-p and Top-K sampling"
      ],
      "metadata": {
        "id": "ThPtcj7MYiqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_output_top_k_top_p = gpt2.generate(\n",
        "    input_ids,\n",
        "    max_length = 2*MAX_LEN,\n",
        "    top_p = 0.85,\n",
        "    top_k = 50,\n",
        "    do_sample = True,\n",
        "    num_return_sequences = 5\n",
        ")\n",
        "\n",
        "print(\"*\" * 100)\n",
        "\n",
        "print(tokenizer.decode(sample_output_top_k_top_p[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaoqDSIYYloa",
        "outputId": "570ae203-bdec-4a5c-9a9d-2ceb430ffa11"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****************************************************************************************************\n",
            "I don't know about you, but there's only one thing I want to do after a long day of work. I want to get home and drink a beer with my wife, and enjoy some TV. If only you had that option with you, I'd be watching it with you.\"\n",
            "\n",
            "But I didn't have that option with him, and I wasn't ready to accept it. I needed to find a better solution, and I didn't know how to go about doing that.\n",
            "\n",
            "So I began looking around for an affordable cable or satellite provider that would provide a DVR for me, with a decent price tag. Then, one day in late 2012, I discovered Z\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPT-2 Text Generation"
      ],
      "metadata": {
        "id": "XyDdu1xfaehd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1 = \"Write a script for Goodfellas if written by Steven Spielberg\""
      ],
      "metadata": {
        "id": "vgoNSKrBahHR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer.encode(prompt1, return_tensors='tf')\n",
        "\n",
        "sample_output_prompt1 = gpt2.generate(\n",
        "    input_ids,\n",
        "    do_sample = True,\n",
        "    top_k = 50,\n",
        "    top_p = 0.85,\n",
        "    max_length = 2*MAX_LEN\n",
        ")\n",
        "\n",
        "print(\"*\" * 100)\n",
        "\n",
        "print(tokenizer.decode(sample_output_prompt1[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVT21Zl1atg2",
        "outputId": "732ab9ab-16e1-4ee0-bbd6-77326398bca3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****************************************************************************************************\n",
            "Write a script for Goodfellas if written by Steven Spielberg (with an \"E\" for \"epic,\" a \"S\" for \"semi-final,\" and a \"P\" for \"pitch\"), \"Lincoln\" if written by Alexander Payne (with an \"E\" for \"epic,\" a \"S\" for \"semi-final,\" and a \"P\" for \"pitch\"), or \"Lincoln\" and \"The Post\" if written by Ben Franklin (with an \"E\" for \"epic,\" a \"S\" for \"semi-final,\" and a \"P\" for \"pitch\").\n",
            "\n",
            "Please contact us if you are\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt2 = \"For today’s homework assignment, please describe the reasons for the US Civil War.\""
      ],
      "metadata": {
        "id": "LyTtWwylemw2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer.encode(prompt2, return_tensors=\"tf\")\n",
        "\n",
        "sample_output_prompt2 = gpt2.generate(\n",
        "    input_ids,\n",
        "    do_sample = True,\n",
        "    top_p = 0.85,\n",
        "    top_k = 50,\n",
        "    max_length = MAX_LEN\n",
        ")\n",
        "\n",
        "print(\"*\" * 100)\n",
        "\n",
        "print(tokenizer.decode( sample_output_prompt2[0], skip_special_token=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15jj8pk-e5AQ",
        "outputId": "045aeb53-0483-4c22-cccf-d969c4c027c8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****************************************************************************************************\n",
            "For today’s homework assignment, please describe the reasons for the US Civil War. If you are unable to do this, please write a letter explaining your answer.\n",
            "\n",
            "Answer the following question to find out how you know the Civil War was a war for the right of Americans to own firearms. Explain your answer in your letter.\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}