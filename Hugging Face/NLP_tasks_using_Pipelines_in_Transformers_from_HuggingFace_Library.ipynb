{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-Z5MKOE8wgQ",
        "outputId": "256bb7f3-77ef-4dac-fe47-2755e849f2cf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "blPW47SG8IiV"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Text Classification**"
      ],
      "metadata": {
        "id": "h7QYxpJ_9Ym6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classificationModel = pipeline('text-classification')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIzpM3gf9BJV",
        "outputId": "023c8304-8b1c-492d-9c31-3b38bb2164f2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
            "pip install xformers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classificationModel(['Today is my birthday', 'I lost my wallet'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byOaLtDG9Psj",
        "outputId": "32305b84-6f14-4fd1-b730-5bcb3fc5c56c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9993195533752441},\n",
              " {'label': 'NEGATIVE', 'score': 0.9997218251228333}]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Text Summarization**"
      ],
      "metadata": {
        "id": "8uh9ss3U9cpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summarizationModel = pipeline('summarization')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyXSBaR79cCF",
        "outputId": "0857fe72-f85c-4dff-d1f7-24fa65f9c779"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "articleOnRajini = '''\n",
        "  Rajinikanth, born as Shivaji Rao Gaekwad, is a legendary actor who has achieved an iconic status in the Indian film industry. Hailing from a modest background,\n",
        "  Rajinikanth's journey to stardom is a testament to his indomitable spirit and extraordinary talent. Starting his career in the 1970s, Rajinikanth initially played supporting roles\n",
        "  but soon caught the attention of audiences with his unique style, charisma, and unmatched screen presence. His magnetic on-screen persona, coupled with his ability to effortlessly\n",
        "  transition between intense action sequences and comedic moments, endeared him to fans across the nation. With blockbuster hits like \"Baasha,\" \"Padayappa,\" and \"Enthiran,\"\n",
        "  Rajinikanth's popularity soared to new heights, transcending language barriers and earning him a massive fan following. Fondly referred to as \"Thalaivar\" (meaning \"The Boss\") by his\n",
        "  admirers, Rajinikanth's rise to stardom is a true rags-to-riches story, inspiring millions with his talent, humility, and larger-than-life image on and off the silver screen.\n",
        "  Rajinikanth's rise to stardom is not only attributed to his acting prowess but also to his ability to connect with the masses on a deeper level. His dialogue delivery, characterized by\n",
        "  unique mannerisms and powerful punch lines, has become legendary and has been celebrated by fans through countless imitations and tributes. Rajinikanth's movies often feature a blend of\n",
        "  action, drama, and social messages, which struck a chord with the audience, making him a symbol of hope and inspiration. His larger-than-life persona and his trademark style, including\n",
        "  his iconic sunglasses, have become symbols of Rajinikanth's cinematic legacy. Outside of his acting career, Rajinikanth has also demonstrated his philanthropic side by actively\n",
        "  participating in charitable endeavors and social causes, further endearing him to his fans. Even after decades in the industry, Rajinikanth continues to command a devoted fan base,\n",
        "  and his films generate immense anticipation and excitement. Rajinikanth's rise to stardom serves as a testament to his unparalleled talent, dedication, and the impact he has had on the\n",
        "  hearts and minds of people, solidifying his position as one of India's most beloved and revered actors.\n",
        "'''"
      ],
      "metadata": {
        "id": "3H2-g7Rz9Xkx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summOnRajini = summarizationModel(articleOnRajini)"
      ],
      "metadata": {
        "id": "j8nTXIJZ-rvj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summOnRajini"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-CfgRNo_VtP",
        "outputId": "b4966171-2d69-4ebe-88df-a6c76763bcdf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': ' Rajinikanth, born Shivaji Rao Gaekwad, is a legendary actor who has achieved an iconic status in the Indian film industry . His rise to stardom is a true rags-to-riches story, inspiring millions with his talent, humility, and larger-than-life image on and off the silver screen . His movies often feature a blend of action, drama, and social messages, making him a symbol of hope and inspiration .'}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conversation**"
      ],
      "metadata": {
        "id": "OO9urZEYQizr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, Conversation\n",
        "\n",
        "#Using Microsoft's chatbot\n",
        "chatbotModel = pipeline(model='microsoft/DialoGPT-medium')\n",
        "conversation = Conversation('Going to the movies - any suggestion')\n",
        "conversation = chatbotModel(conversation)\n",
        "conversation.generated_responses\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8GWBnU8Qkgb",
        "outputId": "5449a0f1-264d-4ca6-ce2b-4f07f0d4bca6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The Big Lebowski']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.add_user_input(\"How will you rate the movie\")\n",
        "conversation = chatbotModel(conversation)\n",
        "conversation.generated_responses[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "KsufQ8aYSbRr",
        "outputId": "29cc19f9-36b2-47ca-93f9-f2e944a8341f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"It's a masterpiece\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.add_user_input(\"Thanks. Who are the actors in the movie\")\n",
        "conversation = chatbotModel(conversation)\n",
        "conversation.generated_responses[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "mnsWb_G3SrPk",
        "outputId": "f2297d02-4157-45ef-b6dc-85417af85ee8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I don't know, but I'm sure they're great.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.add_user_input(\"Can you wish me. Today is my birthday\")\n",
        "conversation = chatbotModel(conversation)\n",
        "conversation.generated_responses[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "YiXpk65rTIvi",
        "outputId": "47bda7a7-f465-4f92-c76b-bae6c68bad45"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Happy birthday!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fill Mask (Fill in the blanks)**\n",
        "\n"
      ],
      "metadata": {
        "id": "K1cGPZOBWs7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fillMaskModel = pipeline(model='bert-base-uncased')\n",
        "fillMaskModel('I want to go to the [MASK] today.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NogPqpUnWwM_",
        "outputId": "36328618-77a6-415a-e837-0efb24b6f77e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.09256961196660995,\n",
              "  'token': 5691,\n",
              "  'token_str': 'movies',\n",
              "  'sequence': 'i want to go to the movies today.'},\n",
              " {'score': 0.06416574865579605,\n",
              "  'token': 2902,\n",
              "  'token_str': 'hospital',\n",
              "  'sequence': 'i want to go to the hospital today.'},\n",
              " {'score': 0.03832973912358284,\n",
              "  'token': 3509,\n",
              "  'token_str': 'beach',\n",
              "  'sequence': 'i want to go to the beach today.'},\n",
              " {'score': 0.03663478046655655,\n",
              "  'token': 3075,\n",
              "  'token_str': 'library',\n",
              "  'sequence': 'i want to go to the library today.'},\n",
              " {'score': 0.036588553339242935,\n",
              "  'token': 9726,\n",
              "  'token_str': 'gym',\n",
              "  'sequence': 'i want to go to the gym today.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question Answering**"
      ],
      "metadata": {
        "id": "QkslJg6wX22H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questAndAnswerModel = pipeline(model='deepset/roberta-base-squad2')\n",
        "questAndAnswerModel(question='Where do I live', context='My name is Randomguy. I live in Miami.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7qjGppVX7BS",
        "outputId": "7b9815c4-e629-495c-ae55-8c87ec08909e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.8643614053726196, 'start': 32, 'end': 37, 'answer': 'Miami'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Text Classification**"
      ],
      "metadata": {
        "id": "EZhG9Bp7ZBgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "textClassificationModel = pipeline('text-classification')\n",
        "textClassificationModel('The convoluted legal jargon employed in the document makes it nearly impossible to decipher the true intent of the legislation.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsuFBKZ1ZbQG",
        "outputId": "0fa59fb0-48fa-4d75-df06-7a539164a2ed"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'NEGATIVE', 'score': 0.9995452761650085}]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "textClassificationModel('The convoluted legal jargon employed in the document makes it nearly impossible to decipher the true intent of the legislation.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7-KNMFBZ8AV",
        "outputId": "ee84534b-9ba3-4385-84fb-daaca660a387"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'NEGATIVE', 'score': 0.9995452761650085}]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "textClassificationModel('The unparalleled beauty of the sunset painted a breathtaking tapestry across the horizon, leaving everyone in awe of natures artistry.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fgm4lV3jaETE",
        "outputId": "bd60d689-a29f-495c-93a6-bda65e4ca118"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9997811913490295}]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Text to Text Generation**\n",
        "\n"
      ],
      "metadata": {
        "id": "rFCAG9AJaYcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelWithLMHead"
      ],
      "metadata": {
        "id": "KrjWiqd9cv1e"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gmg1ByYoAyv",
        "outputId": "ceefb2a6-5a18-4848-c6fa-8e49e4c084b6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "autoTokenizer = AutoTokenizer.from_pretrained('mrm8488/t5-base-finetuned-question-generation-ap')\n",
        "textToTextGenModel = AutoModelWithLMHead.from_pretrained('mrm8488/t5-base-finetuned-question-generation-ap')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYEhEjEdnbVL",
        "outputId": "27611cd1-444a-483f-9308-93f18ef1dd56"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/modeling_auto.py:1362: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  warnings.warn(\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_question(answer, context):\n",
        "  input_text = \"answer:%s context:%s </s>\" % (answer, context)\n",
        "  features = autoTokenizer([input_text], return_tensors='pt')\n",
        "\n",
        "  output = textToTextGenModel.generate(\n",
        "      input_ids=features['input_ids'],\n",
        "      attention_mask = features['attention_mask'],\n",
        "      max_length=40\n",
        "  )\n",
        "\n",
        "  return autoTokenizer.decode(output[0])"
      ],
      "metadata": {
        "id": "_FTTZxcJpWJl"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"Djokovic has won 23 Grand Slams, the most among the men's players.\"\n",
        "answer = \"Djokovic\"\n",
        "\n",
        "get_question(answer, context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "MS5cfOgLqysc",
        "outputId": "3172703b-a7c1-40ba-ac80-d9a0235d5948"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<pad> question: Who has won the most Grand Slams?</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ]
}